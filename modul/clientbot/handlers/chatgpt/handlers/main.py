import math
import os
from pathlib import Path
import re
from aiogram import Bot, flags
from aiogram.types import Message, URLInputFile, FSInputFile
from aiogram.dispatcher.fsm.context import FSMContext
from aiogram.utils.i18n import gettext as _
from aiogram.utils.i18n import lazy_gettext as __

from clientbot.handlers.chatgpt.shortcuts import add_record
from clientbot.handlers.chatgpt.states import AIState
from clientbot.keyboards.reply_kb import main_menu
from clientbot.shortcuts import get_bot_by_token, get_user, have_one_module
from db import models
from clientbot.handlers.chatgpt.keyboards.reply_kbrds import get_chatgt_main_kbrd
from loader import client_bot_router, robot

from clientbot.handlers.chatgpt.keyboards.inline_kbrds import get_kbrd_agree, get_kbrd_ai_balance, get_kbrd_ai_cabinet, \
    get_kbrd_chat_type, get_kbrd_help, get_kbrd_speech_voices
from clientbot.utils.ChatGPT import MODEL_TYPE, PRICING, ChatGPT
from config import scheduler
from loader import bot_session


async def get_cabinet_text(fisrt_name: str, last_name: str, user_id: int):
    me = await get_user(user_id)
    return _("üë§ –ü—Ä–æ—Ñ–∏–ª—å: {fisrt_name} {last_name}\n\n‚ö°Ô∏è –ë–∞–ª–∞–Ω—Å: {limit} ‚≠ê").format(fisrt_name=fisrt_name or '',
                                                                                   last_name=last_name or '',
                                                                                   limit=me.current_ai_limit)


async def main_cabinet(message: Message, ):
    await message.answer(
        await get_cabinet_text(message.from_user.first_name, message.from_user.last_name, message.from_user.id),
        reply_markup=get_chatgt_main_kbrd())


@client_bot_router.message(text=__("üåê –ò–ò"))
@flags.rate_limit(key="ai")
async def music_menu(message: Message, state: FSMContext):
    await main_cabinet(message)


@client_bot_router.message(text=__("üîç –ì—É–≥–ª –ø–æ–∏—Å–∫"))
@flags.rate_limit(key="ai-google-search")
async def music_menu(message: Message, state: FSMContext):
    user = await get_user(message.from_user.id)
    await message.answer(
        _('üîç –ì—É–≥–ª –ø–æ–∏—Å–∫:\n\n'
          'üîò –ù–∞–ø–∏—à–∏—Ç–µ –∑–∞–ø—Ä–æ—Å, –∞ –±–æ—Ç —Å–æ—Å—Ç–∞–≤–∏—Ç –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç–∏—Ç –Ω–∞ –Ω–µ–≥–æ, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—è —Å—Å—ã–ª–∫–∏.\n\n'
          '‚ö°Ô∏è 1 –∑–∞–ø—Ä–æ—Å = {price} ‚≠ê\n\n'
          '–û—Å—Ç–∞–ª–æ—Å—å: {limit} ‚≠ê\n\n').format(price=PRICING["google_search"]["without_context"],
                                            limit=user.current_ai_limit),
        reply_markup=get_kbrd_chat_type("google_search", use_context=False)
    )


@client_bot_router.message(text=__("üé• –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —é—Ç—É–±"))
@flags.rate_limit(key="youtube-transcription")
async def music_menu(message: Message, state: FSMContext):
    user = await get_user(message.from_user.id)
    await message.answer(
        _('ü§ñ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —é—Ç—É–± –≤–∏–¥–µ–æ :\n\n'
          'üìã –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∞–º–∞—è –ø–æ—Å–ª–µ–¥–Ω—è—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å GPT-3.5 turbo.\n\n'
          'üîò –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å—Å—ã–ª–∫—É –Ω–∞ YouTube –≤–∏–¥–µ–æ.\n\n'
          '‚ö°Ô∏è 10 –º–∏–Ω—É—Ç = {price} ‚≠ê\n\n'
          '–û—Å—Ç–∞–ª–æ—Å—å: {limit} ‚≠ê\n\n').format(price=PRICING["youtube_transcription"]["without_context"],
                                            limit=user.current_ai_limit),
        reply_markup=get_kbrd_chat_type("youtube_transcription", use_context=False)
    )


@client_bot_router.message(text=__("‚òÅ –ß–∞—Ç —Å GPT-4"))
@flags.rate_limit(key="chat-gpt4")
async def music_menu(message: Message, state: FSMContext):
    user = await get_user(message.from_user.id)
    await message.answer(
        _('ü§ñ GPT-4:\n\n'
          'üìã –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∞–º–∞—è –ø–æ—Å–ª–µ–¥–Ω—è—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å GPT-4 Turbo.\n\n'
          'üîò –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç.\n\n'
          'üóØ –ß–∞—Ç –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ‚Äî –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∫–∞–∂–¥—ã–π –≤–∞—à –∑–∞–ø—Ä–æ—Å –∫–∞–∫ –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥.\n'
          '‚ö°Ô∏è 1 –∑–∞–ø—Ä–æ—Å = {price} ‚≠ê\n\n'
          'üí¨ –ß–∞—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º ‚Äî –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤–∞—à–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞.\n'
          '‚ö°Ô∏è 1 –∑–∞–ø—Ä–æ—Å = {price2} ‚≠ê\n\n'
          '–û—Å—Ç–∞–ª–æ—Å—å: {limit} ‚≠ê\n\n'
          '‚îî –í—ã–±–µ—Ä–∏—Ç–µ —á–∞—Ç:').format(price=PRICING["gpt4"]["without_context"], price2=PRICING["gpt4"]["with_context"],
                                    limit=user.current_ai_limit),
        reply_markup=get_kbrd_chat_type("gpt4")
    )


@client_bot_router.message(text=__("‚òÅ –ß–∞—Ç —Å GPT-3.5"))
@flags.rate_limit(key="chat-gpt3.5")
async def music_menu(message: Message, state: FSMContext):
    user = await get_user(message.from_user.id)
    await message.answer(
        _('ü§ñ GPT-3.5:\n\n'
          'üìã –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∞–º–∞—è —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å GPT-3.5 Turbo.\n\n'
          'üîò –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.\n\n'
          'üóØ –ß–∞—Ç –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ‚Äî –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∫–∞–∂–¥—ã–π –≤–∞—à –∑–∞–ø—Ä–æ—Å –∫–∞–∫ –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥.\n'
          '‚ö°Ô∏è 1 –∑–∞–ø—Ä–æ—Å = {price} ‚≠ê\n\n'
          'üí¨ –ß–∞—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º ‚Äî –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤–∞—à–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞.\n'
          '‚ö°Ô∏è 1 –∑–∞–ø—Ä–æ—Å = {price2} ‚≠ê\n\n'
          '–û—Å—Ç–∞–ª–æ—Å—å: {limit} ‚≠ê\n\n'
          '‚îî –í—ã–±–µ—Ä–∏—Ç–µ —á–∞—Ç:').format(price=PRICING["gpt3"]["without_context"], price2=PRICING["gpt3"]["with_context"],
                                    limit=user.current_ai_limit),
        reply_markup=get_kbrd_chat_type("gpt3")
    )


@client_bot_router.message(text=__("üé® –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ñ–æ—Ç–æ [DALL-E]"))
@flags.rate_limit(key="gen-dalle-photo")
async def music_menu(message: Message, state: FSMContext):
    user = await get_user(message.from_user.id)
    await message.answer(
        _('ü§ñ DALL¬∑E:\n\n'
          'üìã DALL¬∑E 3 ‚Äî —ç—Ç–æ –Ω–µ–π—Ä–æ—Å–µ—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∏—Å–∫—É—Å—Å—Ç–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è.\n\n'
          'üîò –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ: —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –ª–∏–±–æ —Ñ–æ—Ç–æ.\n'
          '‚ö°Ô∏è 1 –∑–∞–ø—Ä–æ—Å = {price} ‚≠ê\n\n'
          '–û—Å—Ç–∞–ª–æ—Å—å: {user.current_ai_limit} ‚≠ê').format(price=PRICING["dalle"]["without_context"],
                                                        limit=user.current_ai_limit),
        reply_markup=get_kbrd_chat_type("dalle", use_context=False)
    )


@client_bot_router.message(text=__("üó£Ô∏è–ì–æ–ª–æ—Å–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫"))
@flags.rate_limit(key="ai-assistant")
async def music_menu(message: Message, state: FSMContext):
    user = await get_user(message.from_user.id)
    await message.answer( \
        _('ü§ñ –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç:\n\n'
          'üìã –ü–µ—Ä–≤—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤ Telegram –Ω–∞ –±–∞–∑–µ ChatGPT.\n\n'
          'üîò –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.\n'
          '‚ö°Ô∏è 1 –∑–∞–ø—Ä–æ—Å = {price} ‚≠ê\n\n'
          '–û—Å—Ç–∞–ª–æ—Å—å: {limit} ‚≠ê').format(price=PRICING["assistant"]["without_context"], limit=user.current_ai_limit),
        reply_markup=get_kbrd_chat_type("assistant", use_context=False)
    )


@client_bot_router.message(text=__("üó®Ô∏è –¢–µ–∫—Å—Ç –≤ –∞—É–¥–∏–æ"))
@flags.rate_limit(key="text-to-speech")
async def music_menu(message: Message, state: FSMContext):
    user = await get_user(message.from_user.id)
    await message.answer(
        _('ü§ñ –¢–µ–∫—Å—Ç –≤ –≥–æ–ª–æ—Å:\n\n'
          'üìã –ú–æ–¥–µ–ª—å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∑–≤—É—á–∞—â–∏–π —É—Å—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç.\n'
          '‚ö°Ô∏è 1 –∑–∞–ø—Ä–æ—Å = {price} ‚≠ê\n\n'
          '–û—Å—Ç–∞–ª–æ—Å—å: {limit} ‚≠ê\n\n'
          '‚îî –í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å:').format(price=PRICING["text-to-speech"]["without_context"], limit=user.current_ai_limit),
        reply_markup=get_kbrd_speech_voices()
    )


@client_bot_router.message(text="üîâ –ê—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç")
@flags.rate_limit(key="speech-to-text")
async def music_menu(message: Message, state: FSMContext):
    user = await get_user(message.from_user.id)
    await message.answer( \
        'ü§ñ –ì–æ–ª–æ—Å –≤ —Ç–µ–∫—Å—Ç:\n\n'
        'üìã –ú–æ–¥–µ–ª—å –ò–ò, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤–∞—à–µ –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç.\n'
        f'‚ö°Ô∏è 1 –∑–∞–ø—Ä–æ—Å = {PRICING["speech-to-text"]["without_context"]} ‚≠ê\n\n'
        f'–û—Å—Ç–∞–ª–æ—Å—å: {user.current_ai_limit} ‚≠ê\n\n'
        '‚îî –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:',
        reply_markup=get_kbrd_chat_type("speech-to-text", use_context=False)
    )


@client_bot_router.message(text=__("‚ÑπÔ∏è –ü–æ–º–æ—â—å"))
@flags.rate_limit(key="ai-help")
async def music_menu(message: Message, state: FSMContext):
    bot = Bot.get_current()
    bot_db = await get_bot_by_token(bot.token)
    owner: models.MainBotUser = await bot_db.owner
    user: models.User = await owner.user
    link = f"https://t.me/{user.username}" if user.username else f"tg://user?id={user.uid}"
    await message.answer(_("‚ÑπÔ∏è –ü–æ–º–æ—â—å:"), reply_markup=get_kbrd_help(link))


async def run_ai_query(bot_token: str, user_id: int, message: str, context: bool, message_id: int, model_type: str,
                       voice: str = None, cost: float = None):
    async with Bot(bot_token, bot_session, parse_mode="HTML").context(auto_close=False) as bot_:
        try:
            if model_type in ['gpt4', 'gpt3']:
                await bot_.send_chat_action(user_id, "typing")
                # async with ChatActionSender.typing(chat_id=user_id) as c:
                model = MODEL_TYPE[model_type]
                gpt_answer = robot.chat_gpt(user_id=user_id, message=message, model=model, context=context)
                await bot_.send_message(user_id, gpt_answer, reply_to_message_id=message_id, parse_mode='Markdown')
                await add_record(bot_token, user_id, message, models.GPTTypeEnum.REQUEST)
            elif model_type == 'dalle':
                await bot_.send_chat_action(user_id, "upload_photo")
                pic = robot.text_to_picture(message)
                await bot_.send_photo(user_id, URLInputFile(pic.data[0].url), reply_to_message_id=message_id,
                                      parse_mode='Markdown', request_timeout=5000000)
                await add_record(bot_token, user_id, message, models.GPTTypeEnum.PICTURE)
            elif model_type == 'text-to-speech':
                await bot_.send_chat_action(user_id, "record_voice")
                audio = robot.text_to_audio(voice, message)
                name = f"{user_id}_{message_id}.ogg"
                audio.stream_to_file(name)
                await bot_.send_voice(user_id, FSInputFile(name), reply_to_message_id=message_id)
                os.remove(name)
                await add_record(bot_token, user_id, message, models.GPTTypeEnum.TEXT_TO_SPEECH)
            elif model_type == 'speech-to-text':
                await bot_.send_chat_action(user_id, "typing")
                name = f"{user_id}_{message_id}.ogg"
                await bot_.download_file(message, name)
                audio = robot.audio_to_text(Path(name))
                await bot_.send_message(user_id, audio, reply_to_message_id=message_id, parse_mode='Markdown')
                os.remove(name)
                await add_record(bot_token, user_id, message, models.GPTTypeEnum.SPEECH_TO_TEXT)
            elif model_type == 'assistant':
                await bot_.send_chat_action(user_id, "record_voice")
                name = f"{user_id}_{message_id}.ogg"
                await bot_.download_file(message, name)
                audio = robot.audio_to_text(Path(name))
                model = MODEL_TYPE["gpt4"]
                gpt_answer = robot.chat_gpt(user_id=user_id, message=audio, model=model, context=False)
                audio = robot.text_to_audio("echo", gpt_answer)
                audio.stream_to_file(f"answer-{name}")
                await bot_.send_voice(user_id, FSInputFile(f"answer-{name}"), reply_to_message_id=message_id)
                os.remove(name)
                os.remove(f"answer-{name}")
                await add_record(bot_token, user_id, message, models.GPTTypeEnum.ASSISTANT)
            elif model_type == 'google_search':
                res = robot.google_search(user_id, message)
                await bot_.send_message(user_id, res, reply_to_message_id=message_id, parse_mode='HTML')
        except Exception as e:
            user = await get_user(user_id)
            user.current_ai_limit += cost
            await user.save()
            await bot_.send_message(user_id, f"–û—à–∏–±–∫–∞: {e}\n–ú—ã –≤–µ—Ä–Ω—É–ª–∏: {cost} üåü", reply_to_message_id=message_id)


async def run_ai_vidio_summary(bot_token: str, user_id: int, video_id: str, message_id: int, cost: int):
    async with Bot(bot_token, bot_session, parse_mode="HTML").context(auto_close=False) as bot_:
        try:
            await bot_.send_chat_action(user_id, "typing")
            result = robot.extract_youtube_transcript(user_id, video_id)
            await bot_.send_message(user_id, result, reply_to_message_id=message_id, parse_mode='Markdown')
        except Exception as e:
            user = await get_user(user_id)
            user.current_ai_limit += cost
            await user.save()
            await bot_.send_message(user_id, _("–û—à–∏–±–∫–∞: {e}\n–ú—ã –≤–µ—Ä–Ω—É–ª–∏: {cost} üåü").format(e=e, cost=cost),
                                    reply_to_message_id=message_id)


@client_bot_router.message(state=AIState.input_prompt)
@flags.rate_limit(key="input-prompt")
async def music_menu(message: Message, state: FSMContext):
    user_id = message.from_user.id
    bot = Bot.get_current()
    bot_db = await get_bot_by_token(bot.token)
    if message.text:
        if message.text == _('–û—Ç–º–µ–Ω–∏—Ç—å –≤–≤–æ–¥'):
            if have_one_module(bot_db, "chatgpt"):
                await message.answer(_("–û—Ç–º–µ–Ω–µ–Ω–æ"), reply_markup=await main_menu(user_id))
            else:
                await main_cabinet(message)
            await state.clear()
            return

    user = await get_user(user_id)
    data = await state.get_data()
    model_type = data.get("model")
    voice = ""
    use_context = False
    content = ""
    if model_type == 'youtube_transcription':
        duration = ChatGPT.get_youtube_duration(message.text)
        sum = math.ceil(duration / PRICING["youtube_transcription"]["minutes"]) * PRICING["youtube_transcription"][
            "without_context"]
        video_id_match = re.search(r"(?<=v=)[^&]+|(?<=youtu.be/)[^?|\n]+", message.text)
        video_id = video_id_match.group(0) if video_id_match else None
        if video_id is None:
            await message.answer(_("–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Å—Å—ã–ª–∫—É"))
        await message.answer(
            _("‚åõÔ∏è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ: {duration} –º–∏–Ω—É—Ç\r\n–°—Ç–æ–∏–º–æ—Å—Ç—å: {sum}‚≠êÔ∏è").format(duration=duration, sum=sum),
            reply_markup=get_kbrd_agree(video_id, sum, message.message_id))
        return
    if model_type == 'youtube_transcription':
        content = message.text
    elif model_type == 'text-to-speech':
        voice = data.get("voice")
        content = message.text
    elif model_type in ['speech-to-text', 'assistant']:
        if not message.voice:
            await message.answer(_("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"))
            return
        content = (await bot.get_file(message.voice.file_id)).file_path
    else:
        use_context = data.get("use_context")
        content = message.text
    cost = PRICING[model_type]["with_context" if use_context else "without_context"]
    if user.current_ai_limit < cost:
        bot_db = await get_bot_by_token(bot.token)
        await message.answer(_("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ä–µ–¥—Å—Ç–≤"),
                             reply_markup=await get_kbrd_ai_balance(message.from_user.id, bot_db.percent))
        await state.clear()
        return
    user.current_ai_limit -= cost
    await user.save()
    await message.answer(
        _("–ó–∞–ø—Ä–æ—Å –ø—Ä–∏–Ω—è—Ç, –æ–∂–∏–¥–∞–π—Ç–µ –æ—Ç–≤–µ—Ç–∞\n–û—Å—Ç–∞–ª–æ—Å—å: {limit} ‚≠ê\n–í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –≤–≤–æ–¥, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫–∞ '–û—Ç–º–µ–Ω–∏—Ç—å –≤–≤–æ–¥' —á—Ç–æ–±—ã –ø—Ä–µ–∫—Ä–∞—Ç–∏—Ç—å").format(
            limit=user.current_ai_limit))
    scheduler.add_job(run_ai_query,
                      args=(bot.token, user_id, content, use_context, message.message_id, model_type, voice, cost),
                      max_instances=1, misfire_grace_time=60, coalesce=False, id=f"{user_id}_{message.message_id}",
                      replace_existing=False)


@client_bot_router.message(text=__('üîã –ë–∞–ª–∞–Ω—Å'))
@flags.rate_limit(key="ai-balance")
async def music_menu(message: Message, state: FSMContext):
    await message.answer(
        await get_cabinet_text(message.from_user.first_name, message.from_user.last_name, message.from_user.id),
        reply_markup=get_kbrd_ai_cabinet())
